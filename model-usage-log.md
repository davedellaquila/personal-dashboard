# Model Usage & Cost Tracking

Started: 2026-02-07

## Purpose
Comparing GPT-5.2 vs Claude Opus 4.5 costs over time to optimize for budget.

## Session Log

### 2026-02-07 Full Day (GPT-5.2)
- **Model**: openai/gpt-5.2-chat-latest
- **Session start**: ~06:37 PST
- **Session check**: 2:19 PM PST
- **Tasks**: 
  - Alex Finn YouTube search
  - Twitter API setup (bearer token, monitor script)
  - Daily AI digest cron job setup
  - Airtable updates (Feb 7 log)
  - Model cost discussion
  - Apple Music playlist inquiry
- **Context Usage**: 169k / 1.0M tokens (17%)
- **Compactions**: 0 (clean history)
- **Last turn**: 10 input / 494 output tokens
- **Estimated cost** (rough, per 169k input):
  - Input: ~$0.51-0.85 (at $3-5/M rate)
  - Output: Tracking needed for full session
- **Notes**: First full-day GPT-5.2 test after switching from Claude Sonnet 4.5. Much longer, feature-rich session (Twitter, Airtable, cron). Good for cost comparison.

---

## Cost Estimates (per 1M tokens)
- **GPT-5.2**: ~$3-5 input / ~$15 output
- **Claude Opus 4.5**: ~$15 input / ~$75 output
- **Claude Sonnet 4.5**: ~$3 input / ~$15 output

## Notes
- Previous sessions used Claude Sonnet 4.5 (default)
- OpenAI models already paid for via subscription
- Will track for several days to compare real-world usage
